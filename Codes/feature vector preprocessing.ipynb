{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a470aa",
   "metadata": {},
   "source": [
    "# Feature Vector Data Preproecessing Pipeline\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d8e7f8",
   "metadata": {},
   "source": [
    "## Step-1: Install dependencies\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6395aac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 0. Install / Import Dependencies\n",
    "!pip install -q scikit-learn pandas matplotlib numpy seaborn\n",
    "!pip install -q opendatasets  # For Kaggle dataset download\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4999b25c",
   "metadata": {},
   "source": [
    "## Step-2: Load Feature Vectors\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fde9f2",
   "metadata": {},
   "source": [
    "### Dowload Dataset from Kaggle -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e71702",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset Selection - Choose which dataset to use\n",
    "DATASET_CHOICE = 'ember'  # Change to 'bodmas' to use BODMAS dataset\n",
    "\n",
    "# Kaggle dataset URLs\n",
    "EMBER_URL = 'https://www.kaggle.com/datasets/dhoogla/ember-2018-v2-features'\n",
    "BODMAS_URL = 'https://www.kaggle.com/datasets/dhoogla/bodmas'\n",
    "\n",
    "print(f\"Selected dataset: {DATASET_CHOICE.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78a1c3f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Download datasets from Kaggle (requires Kaggle API credentials)\n",
    "# Note: You need to upload your kaggle.json file to use this\n",
    "import os\n",
    "\n",
    "# Set your Kaggle credentials here\n",
    "os.environ['KAGGLE_USERNAME'] = 'razeenahmed10'\n",
    "os.environ['KAGGLE_KEY'] = '43efe04888a9c1878a4753108e73e0b9'\n",
    "\n",
    "# Then import or use Kaggle API functions that require authentication\n",
    "import opendatasets as od\n",
    "\n",
    "# Proceed with downloading datasets\n",
    "\n",
    "try:\n",
    "    # import opendatasets as od\n",
    "\n",
    "    if DATASET_CHOICE == 'ember':\n",
    "        print(\"Downloading EMBER 2018 v2 Features dataset...\")\n",
    "        od.download(EMBER_URL)\n",
    "        data_path = './ember-2018-v2-features'\n",
    "    else:\n",
    "        print(\"Downloading BODMAS dataset...\")\n",
    "        od.download(BODMAS_URL)\n",
    "        data_path = './bodmas'\n",
    "\n",
    "    print(f\"Dataset downloaded to: {data_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading dataset: {e}\")\n",
    "    print(\"Please manually download the dataset or set up Kaggle API credentials\")\n",
    "\n",
    "    # Manual path setup (if you've already downloaded)\n",
    "    if DATASET_CHOICE == 'ember':\n",
    "        data_path = './ember-2018-v2-features'  # Adjust path as needed\n",
    "    else:\n",
    "        data_path = './bodmas'  # Adjust path as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5501a4",
   "metadata": {},
   "source": [
    "### Load Dataset -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e0c93",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Load EMBER Feature Vectors #it can also be BODMAS\n",
    "from ember import EMBER2018\n",
    "\n",
    "DATA_PATH = '/content/ember2018'  # adjust if needed\n",
    "EMBER2018(DATA_PATH)               # download + extract if not present\n",
    "\n",
    "# Load vectorized features\n",
    "X_train_full = np.memmap(f'{DATA_PATH}/X_train.dat', dtype=np.float32, mode='r', shape=(900000, 2351))\n",
    "y_train_full = np.memmap(f'{DATA_PATH}/y_train.dat', dtype=np.int32,  mode='r', shape=(900000,))\n",
    "\n",
    "mask = y_train_full != -1  # keep labeled rows only\n",
    "X_raw = X_train_full[mask]\n",
    "y_raw = y_train_full[mask]\n",
    "\n",
    "print('Raw EMBER shape:', X_raw.shape, 'Labels:', y_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6daf1a",
   "metadata": {},
   "source": [
    "## Step-3: Train/Test Split\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1fa9e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Train/Test Split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.20, random_state=42, stratify=y_raw)\n",
    "print('Train:', X_train.shape, 'Test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3efc7b",
   "metadata": {},
   "source": [
    "## Step-4: Standardization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7def18",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Standardization (mean=0, std=1)\n",
    "scaler = StandardScaler(copy=False)\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c965513",
   "metadata": {},
   "source": [
    "## Step-5: PCA30 Transformation of Feature Vectors\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96de863",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. PCA â†’ 30 Principal Components\n",
    "pca = PCA(n_components=30, random_state=42, svd_solver='full')\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "print('After PCA:', X_train_pca.shape)\n",
    "print('Variance kept:', pca.explained_variance_ratio_.sum()*100, '%')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
