{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "544272b7",
   "metadata": {},
   "source": [
    "## PE file Preprocessing Pipeline\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1bb529",
   "metadata": {},
   "source": [
    "STAGE-1\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e452f32",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install lief pillow numpy pandas scikit-learn matplotlib pennylane\n",
    "\n",
    "# Import necessary libraries\n",
    "import lief\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All dependencies installed and imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d11081",
   "metadata": {},
   "source": [
    "## Step-1: PE file Parsing using LIEF\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72efce4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def parse_pe_file(pe_file_path):\n",
    "    \"\"\"\n",
    "    Parse PE file using LIEF and extract basic information\n",
    "    \"\"\"\n",
    "    print(f\"Parsing PE file: {pe_file_path}\")\n",
    "    \n",
    "    try:\n",
    "        binary = lief.PE.parse(pe_file_path)\n",
    "        if not binary:\n",
    "            print(\"Failed to parse PE file\")\n",
    "            return None\n",
    "            \n",
    "        print(f\"Successfully parsed PE file\")\n",
    "        print(f\"Number of sections: {len(binary.sections)}\")\n",
    "        print(f\"Entry point: 0x{binary.optional_header.addressof_entrypoint:x}\")\n",
    "        \n",
    "        return binary\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"LIEF parsing error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test the function\n",
    "# binary = parse_pe_file(\"malware_sample.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9dede",
   "metadata": {},
   "source": [
    "## Step-2: Target Section Identification\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db500e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def extract_target_sections(binary):\n",
    "    \"\"\"\n",
    "    Extract the five target sections from PE file\n",
    "    \"\"\"\n",
    "    # Define the five target sections from the paper\n",
    "    target_sections = [\".text\", \".data\", \".rdata\", \".rsrc\", \".reloc\"]\n",
    "    section_data = {}\n",
    "    \n",
    "    # Extract each target section\n",
    "    for target_section in target_sections:\n",
    "        section_found = False\n",
    "        \n",
    "        for section in binary.sections:\n",
    "            # Clean section name (remove null bytes)\n",
    "            section_name = section.name.strip('\\x00')\n",
    "            \n",
    "            if section_name == target_section:\n",
    "                # Extract section content as bytes\n",
    "                content = section.content\n",
    "                section_data[target_section] = content\n",
    "                section_found = True\n",
    "                \n",
    "                print(f\"Found {target_section}: {len(content)} bytes\")\n",
    "                break\n",
    "        \n",
    "        # Handle missing sections (assign -1 score as per paper)\n",
    "        if not section_found:\n",
    "            section_data[target_section] = None\n",
    "            print(f\"Section {target_section} not found - will receive -1 score\")\n",
    "    \n",
    "    return section_data\n",
    "\n",
    "# Test the function\n",
    "# section_data = extract_target_sections(binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd02f08a",
   "metadata": {},
   "source": [
    "## Step-3: Conversion of Section bytes to 8x8 Grayscale Image\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ea3d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def bytes_to_8x8_grayscale_image(byte_content, section_name):\n",
    "    \"\"\"\n",
    "    Convert section bytes to 8x8 grayscale image using Nataraj method\n",
    "    \"\"\"\n",
    "    if byte_content is None:\n",
    "        # Missing section - return None\n",
    "        return None\n",
    "    \n",
    "    # Target: 8x8 = 64 bytes needed\n",
    "    target_pixels = 64\n",
    "    \n",
    "    if len(byte_content) >= target_pixels:\n",
    "        # Take first 64 bytes\n",
    "        pixel_values = list(byte_content[:target_pixels])\n",
    "    else:\n",
    "        # Pad with zeros if insufficient bytes\n",
    "        pixel_values = list(byte_content) + [0] * (target_pixels - len(byte_content))\n",
    "    \n",
    "    # Convert to numpy array and reshape to 8x8\n",
    "    image_array = np.array(pixel_values, dtype=np.uint8).reshape(8, 8)\n",
    "    \n",
    "    # Create PIL Image for visualization/saving\n",
    "    pil_image = Image.fromarray(image_array, mode='L')  # 'L' for grayscale\n",
    "    \n",
    "    return image_array, pil_image\n",
    "\n",
    "# Test the function\n",
    "# img_array, pil_img = bytes_to_8x8_grayscale_image(section_data['.text'], '.text'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa8ce4f",
   "metadata": {},
   "source": [
    "## Step-4: Processing of each sections grayscale image\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ed4292",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def process_sections_to_images(section_data, save_images=False, output_dir=\"./section_images/\"):\n",
    "    \"\"\"\n",
    "    Process all sections to 8x8 grayscale images\n",
    "    \"\"\"\n",
    "    section_images = {}\n",
    "    \n",
    "    if save_images:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for section_name, content in section_data.items():\n",
    "        if content is not None:\n",
    "            result = bytes_to_8x8_grayscale_image(content, section_name)\n",
    "            if result is not None:\n",
    "                img_array, pil_img = result\n",
    "                section_images[section_name] = {\n",
    "                    'array': img_array,\n",
    "                    'pil': pil_img,\n",
    "                    'size': len(content),\n",
    "                    'status': 'found'\n",
    "                }\n",
    "                \n",
    "                # Save image for visualization\n",
    "                if save_images:\n",
    "                    filename = f\"{section_name.replace('.', '')}_section.png\"\n",
    "                    filepath = os.path.join(output_dir, filename)\n",
    "                    pil_img.save(filepath)\n",
    "                    print(f\"Saved {section_name} as 8x8 grayscale image: {filepath}\")\n",
    "                else:\n",
    "                    print(f\"Processed {section_name} to 8x8 grayscale image\")\n",
    "        else:\n",
    "            section_images[section_name] = {\n",
    "                'array': None,\n",
    "                'pil': None,\n",
    "                'size': 0,\n",
    "                'status': 'missing',\n",
    "                'score': -1\n",
    "            }\n",
    "            print(f\"{section_name}: Missing section\")\n",
    "    \n",
    "    return section_images\n",
    "\n",
    "# Test the function\n",
    "# section_images = process_sections_to_images(section_data, save_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b0469",
   "metadata": {},
   "source": [
    "## Step-5: Understanding each Sections Significance\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb0934b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def explain_section_content(section_name, content_size):\n",
    "    \"\"\"\n",
    "    Explain what each PE section typically contains\n",
    "    \"\"\"\n",
    "    explanations = {\n",
    "        \".text\": f\"Executable code and CPU instructions ({content_size} bytes)\",\n",
    "        \".data\": f\"Initialized global and static variables ({content_size} bytes)\",\n",
    "        \".rdata\": f\"Read-only data like string literals and constants ({content_size} bytes)\",\n",
    "        \".rsrc\": f\"Resources like icons, menus, strings - frequently exploited by malware ({content_size} bytes)\",\n",
    "        \".reloc\": f\"Relocation information for loading at different memory addresses ({content_size} bytes)\"\n",
    "    }\n",
    "\n",
    "    return explanations.get(section_name, f\"Unknown section ({content_size} bytes)\")\n",
    "\n",
    "# Display section information\n",
    "for section_name, section_info in section_images.items():\n",
    "    if section_info is not None:\n",
    "        print(f\"{section_name}: {explain_section_content(section_name, section_info['size'])}\")\n",
    "    else:\n",
    "        print(f\"{section_name}: Missing section - will receive -1 score\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d80cc",
   "metadata": {},
   "source": [
    "## Step-6: Complete PE Processing function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd445c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def complete_stage1_processing(pe_file_path, save_images=False, output_dir=\"./section_images/\"):\n",
    "    \"\"\"\n",
    "    Complete Stage-1 pipeline: PE file → Section extraction → 8x8 grayscale images\n",
    "    \"\"\"\n",
    "    print(f\"=== Stage-1 Processing: {pe_file_path} ===\")\n",
    "    \n",
    "    # Step 1: Parse PE file\n",
    "    binary = parse_pe_file(pe_file_path)\n",
    "    if binary is None:\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Extract target sections\n",
    "    section_data = extract_target_sections(binary)\n",
    "    \n",
    "    # Step 3: Convert sections to 8x8 images\n",
    "    section_images = process_sections_to_images(section_data, save_images, output_dir)\n",
    "    \n",
    "    print(\"Stage-1 processing completed successfully!\")\n",
    "    return section_images\n",
    "\n",
    "# Test the complete Stage-1 pipeline\n",
    "# stage1_results = complete_stage1_processing(\"malware_sample.exe\", save_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec44b24",
   "metadata": {},
   "source": [
    "# Stage-2:\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fab52a",
   "metadata": {},
   "source": [
    "## Step-7: Prepare Section Data for PCA30\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a8116",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_section_data_for_pca30(dataset_results, section_name):\n",
    "    \"\"\"\n",
    "    Prepare 8x8 section images for PCA30 training\n",
    "    \"\"\"\n",
    "    section_data = []\n",
    "    missing_indices = []\n",
    "    \n",
    "    for i, pe_results in enumerate(dataset_results):\n",
    "        if pe_results[section_name]['status'] == 'found':\n",
    "            # Get 8x8 image and flatten to 64 features\n",
    "            img_8x8 = pe_results[section_name]['array']  # Shape: (8, 8)\n",
    "            flattened = img_8x8.flatten()  # Shape: (64,)\n",
    "            section_data.append(flattened)\n",
    "        else:\n",
    "            # Track missing sections for later handling\n",
    "            missing_indices.append(i)\n",
    "            # Don't add to training data - will handle separately\n",
    "    \n",
    "    return np.array(section_data), missing_indices\n",
    "\n",
    "# Test the function\n",
    "# valid_data, missing_idx = prepare_section_data_for_pca30([stage1_results], '.text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66144752",
   "metadata": {},
   "source": [
    "# Step-8: Train PCA30 Models\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd01d0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_pca30_models(training_dataset_results, n_components=30):\n",
    "    \"\"\"\n",
    "    Train PCA30 models for each section separately\n",
    "    \"\"\"\n",
    "    target_sections = [\".text\", \".data\", \".rdata\", \".rsrc\", \".reloc\"]\n",
    "    pca_models = {}\n",
    "    pca_explained_variance = {}\n",
    "    \n",
    "    print(\"Training PCA30 models for each section...\")\n",
    "    \n",
    "    for section in target_sections:\n",
    "        print(f\"\\nTraining PCA30 for {section} section...\")\n",
    "        \n",
    "        # Get valid samples (exclude missing sections)\n",
    "        valid_data, missing_idx = prepare_section_data_for_pca30(training_dataset_results, section)\n",
    "        \n",
    "        if len(valid_data) > 0:\n",
    "            # Initialize and fit PCA30: 64 features → 30 components\n",
    "            pca_model = PCA(n_components=n_components, random_state=42)\n",
    "            pca_model.fit(valid_data)  # Input: (n_valid_samples, 64)\n",
    "            pca_models[section] = pca_model\n",
    "            \n",
    "            # Track explained variance\n",
    "            variance_ratios = pca_model.explained_variance_ratio_\n",
    "            total_variance = np.sum(variance_ratios)\n",
    "            pca_explained_variance[section] = {\n",
    "                'individual': variance_ratios,\n",
    "                'total': total_variance,\n",
    "                'n_samples': len(valid_data)\n",
    "            }\n",
    "            \n",
    "            print(f\"{section}: {total_variance:.3f} total variance explained\")\n",
    "            print(f\"Top 5 components: {variance_ratios[:5]}\")\n",
    "            print(f\"Training samples: {len(valid_data)}\")\n",
    "            \n",
    "            # Quality check\n",
    "            if total_variance < 0.85:  # Expect >85% for 30 components\n",
    "                print(f\"WARNING: {section} PCA30 only retains {total_variance:.1%} variance\")\n",
    "        else:\n",
    "            print(f\"WARNING: No valid samples found for {section} section!\")\n",
    "            pca_models[section] = None\n",
    "    \n",
    "    return pca_models, pca_explained_variance\n",
    "\n",
    "# Test the function\n",
    "# pca_models, pca_variance = train_pca30_models([stage1_results])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
