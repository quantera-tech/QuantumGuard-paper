{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "544272b7",
   "metadata": {},
   "source": [
    "## PE file Preprocessing Pipeline\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1bb529",
   "metadata": {},
   "source": [
    "STAGE-1\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e452f32",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install lief pillow numpy pandas scikit-learn matplotlib pennylane\n",
    "\n",
    "# Import necessary libraries\n",
    "import lief\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All dependencies installed and imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d11081",
   "metadata": {},
   "source": [
    "## Step-1: PE file Parsing using LIEF\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72efce4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def parse_pe_file(pe_file_path):\n",
    "    \"\"\"\n",
    "    Parse PE file using LIEF and extract basic information\n",
    "    \"\"\"\n",
    "    print(f\"Parsing PE file: {pe_file_path}\")\n",
    "    \n",
    "    try:\n",
    "        binary = lief.PE.parse(pe_file_path)\n",
    "        if not binary:\n",
    "            print(\"Failed to parse PE file\")\n",
    "            return None\n",
    "            \n",
    "        print(f\"Successfully parsed PE file\")\n",
    "        print(f\"Number of sections: {len(binary.sections)}\")\n",
    "        print(f\"Entry point: 0x{binary.optional_header.addressof_entrypoint:x}\")\n",
    "        \n",
    "        return binary\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"LIEF parsing error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test the function\n",
    "# binary = parse_pe_file(\"malware_sample.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9dede",
   "metadata": {},
   "source": [
    "## Step-2: Target Section Identification\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db500e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def extract_target_sections(binary):\n",
    "    \"\"\"\n",
    "    Extract the five target sections from PE file\n",
    "    \"\"\"\n",
    "    # Define the five target sections from the paper\n",
    "    target_sections = [\".text\", \".data\", \".rdata\", \".rsrc\", \".reloc\"]\n",
    "    section_data = {}\n",
    "    \n",
    "    # Extract each target section\n",
    "    for target_section in target_sections:\n",
    "        section_found = False\n",
    "        \n",
    "        for section in binary.sections:\n",
    "            # Clean section name (remove null bytes)\n",
    "            section_name = section.name.strip('\\x00')\n",
    "            \n",
    "            if section_name == target_section:\n",
    "                # Extract section content as bytes\n",
    "                content = section.content\n",
    "                section_data[target_section] = content\n",
    "                section_found = True\n",
    "                \n",
    "                print(f\"Found {target_section}: {len(content)} bytes\")\n",
    "                break\n",
    "        \n",
    "        # Handle missing sections (assign -1 score as per paper)\n",
    "        if not section_found:\n",
    "            section_data[target_section] = None\n",
    "            print(f\"Section {target_section} not found - will receive -1 score\")\n",
    "    \n",
    "    return section_data\n",
    "\n",
    "# Test the function\n",
    "# section_data = extract_target_sections(binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd02f08a",
   "metadata": {},
   "source": [
    "## Step-3: Conversion of Section bytes to 8x8 Grayscale Image\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ea3d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def bytes_to_8x8_grayscale_image(byte_content, section_name):\n",
    "    \"\"\"\n",
    "    Convert section bytes to 8x8 grayscale image using Nataraj method\n",
    "    \"\"\"\n",
    "    if byte_content is None:\n",
    "        # Missing section - return None\n",
    "        return None\n",
    "    \n",
    "    # Target: 8x8 = 64 bytes needed\n",
    "    target_pixels = 64\n",
    "    \n",
    "    if len(byte_content) >= target_pixels:\n",
    "        # Take first 64 bytes\n",
    "        pixel_values = list(byte_content[:target_pixels])\n",
    "    else:\n",
    "        # Pad with zeros if insufficient bytes\n",
    "        pixel_values = list(byte_content) + [0] * (target_pixels - len(byte_content))\n",
    "    \n",
    "    # Convert to numpy array and reshape to 8x8\n",
    "    image_array = np.array(pixel_values, dtype=np.uint8).reshape(8, 8)\n",
    "    \n",
    "    # Create PIL Image for visualization/saving\n",
    "    pil_image = Image.fromarray(image_array, mode='L')  # 'L' for grayscale\n",
    "    \n",
    "    return image_array, pil_image\n",
    "\n",
    "# Test the function\n",
    "# img_array, pil_img = bytes_to_8x8_grayscale_image(section_data['.text'], '.text'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa8ce4f",
   "metadata": {},
   "source": [
    "## Step-4: Processing of each sections grayscale image\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ed4292",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def process_sections_to_images(section_data, save_images=False, output_dir=\"./section_images/\"):\n",
    "    \"\"\"\n",
    "    Process all sections to 8x8 grayscale images\n",
    "    \"\"\"\n",
    "    section_images = {}\n",
    "    \n",
    "    if save_images:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for section_name, content in section_data.items():\n",
    "        if content is not None:\n",
    "            result = bytes_to_8x8_grayscale_image(content, section_name)\n",
    "            if result is not None:\n",
    "                img_array, pil_img = result\n",
    "                section_images[section_name] = {\n",
    "                    'array': img_array,\n",
    "                    'pil': pil_img,\n",
    "                    'size': len(content),\n",
    "                    'status': 'found'\n",
    "                }\n",
    "                \n",
    "                # Save image for visualization\n",
    "                if save_images:\n",
    "                    filename = f\"{section_name.replace('.', '')}_section.png\"\n",
    "                    filepath = os.path.join(output_dir, filename)\n",
    "                    pil_img.save(filepath)\n",
    "                    print(f\"Saved {section_name} as 8x8 grayscale image: {filepath}\")\n",
    "                else:\n",
    "                    print(f\"Processed {section_name} to 8x8 grayscale image\")\n",
    "        else:\n",
    "            section_images[section_name] = {\n",
    "                'array': None,\n",
    "                'pil': None,\n",
    "                'size': 0,\n",
    "                'status': 'missing',\n",
    "                'score': -1\n",
    "            }\n",
    "            print(f\"{section_name}: Missing section\")\n",
    "    \n",
    "    return section_images\n",
    "\n",
    "# Test the function\n",
    "# section_images = process_sections_to_images(section_data, save_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b0469",
   "metadata": {},
   "source": [
    "## Step-5: Understanding each Sections Significance\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb0934b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def explain_section_content(section_name, content_size):\n",
    "    \"\"\"\n",
    "    Explain what each PE section typically contains\n",
    "    \"\"\"\n",
    "    explanations = {\n",
    "        \".text\": f\"Executable code and CPU instructions ({content_size} bytes)\",\n",
    "        \".data\": f\"Initialized global and static variables ({content_size} bytes)\",\n",
    "        \".rdata\": f\"Read-only data like string literals and constants ({content_size} bytes)\",\n",
    "        \".rsrc\": f\"Resources like icons, menus, strings - frequently exploited by malware ({content_size} bytes)\",\n",
    "        \".reloc\": f\"Relocation information for loading at different memory addresses ({content_size} bytes)\"\n",
    "    }\n",
    "\n",
    "    return explanations.get(section_name, f\"Unknown section ({content_size} bytes)\")\n",
    "\n",
    "# Display section information\n",
    "for section_name, section_info in section_images.items():\n",
    "    if section_info is not None:\n",
    "        print(f\"{section_name}: {explain_section_content(section_name, section_info['size'])}\")\n",
    "    else:\n",
    "        print(f\"{section_name}: Missing section - will receive -1 score\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d80cc",
   "metadata": {},
   "source": [
    "## Step-6: Complete PE Processing function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd445c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def complete_stage1_processing(pe_file_path, save_images=False, output_dir=\"./section_images/\"):\n",
    "    \"\"\"\n",
    "    Complete Stage-1 pipeline: PE file → Section extraction → 8x8 grayscale images\n",
    "    \"\"\"\n",
    "    print(f\"=== Stage-1 Processing: {pe_file_path} ===\")\n",
    "    \n",
    "    # Step 1: Parse PE file\n",
    "    binary = parse_pe_file(pe_file_path)\n",
    "    if binary is None:\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Extract target sections\n",
    "    section_data = extract_target_sections(binary)\n",
    "    \n",
    "    # Step 3: Convert sections to 8x8 images\n",
    "    section_images = process_sections_to_images(section_data, save_images, output_dir)\n",
    "    \n",
    "    print(\"Stage-1 processing completed successfully!\")\n",
    "    return section_images\n",
    "\n",
    "# Test the complete Stage-1 pipeline\n",
    "# stage1_results = complete_stage1_processing(\"malware_sample.exe\", save_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec44b24",
   "metadata": {},
   "source": [
    "# Stage-2:\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fab52a",
   "metadata": {},
   "source": [
    "## Step-7: Prepare Section Data for PCA30\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a8116",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_section_data_for_pca30(dataset_results, section_name):\n",
    "    \"\"\"\n",
    "    Prepare 8x8 section images for PCA30 training\n",
    "    \"\"\"\n",
    "    section_data = []\n",
    "    missing_indices = []\n",
    "    \n",
    "    for i, pe_results in enumerate(dataset_results):\n",
    "        if pe_results[section_name]['status'] == 'found':\n",
    "            # Get 8x8 image and flatten to 64 features\n",
    "            img_8x8 = pe_results[section_name]['array']  # Shape: (8, 8)\n",
    "            flattened = img_8x8.flatten()  # Shape: (64,)\n",
    "            section_data.append(flattened)\n",
    "        else:\n",
    "            # Track missing sections for later handling\n",
    "            missing_indices.append(i)\n",
    "            # Don't add to training data - will handle separately\n",
    "    \n",
    "    return np.array(section_data), missing_indices\n",
    "\n",
    "# Test the function\n",
    "# valid_data, missing_idx = prepare_section_data_for_pca30([stage1_results], '.text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66144752",
   "metadata": {},
   "source": [
    "# Step-8: Train PCA30 Models\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd01d0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_pca30_models(training_dataset_results, n_components=30):\n",
    "    \"\"\"\n",
    "    Train PCA30 models for each section separately\n",
    "    \"\"\"\n",
    "    target_sections = [\".text\", \".data\", \".rdata\", \".rsrc\", \".reloc\"]\n",
    "    pca_models = {}\n",
    "    pca_explained_variance = {}\n",
    "    \n",
    "    print(\"Training PCA30 models for each section...\")\n",
    "    \n",
    "    for section in target_sections:\n",
    "        print(f\"\\nTraining PCA30 for {section} section...\")\n",
    "        \n",
    "        # Get valid samples (exclude missing sections)\n",
    "        valid_data, missing_idx = prepare_section_data_for_pca30(training_dataset_results, section)\n",
    "        \n",
    "        if len(valid_data) > 0:\n",
    "            # Initialize and fit PCA30: 64 features → 30 components\n",
    "            pca_model = PCA(n_components=n_components, random_state=42)\n",
    "            pca_model.fit(valid_data)  # Input: (n_valid_samples, 64)\n",
    "            pca_models[section] = pca_model\n",
    "            \n",
    "            # Track explained variance\n",
    "            variance_ratios = pca_model.explained_variance_ratio_\n",
    "            total_variance = np.sum(variance_ratios)\n",
    "            pca_explained_variance[section] = {\n",
    "                'individual': variance_ratios,\n",
    "                'total': total_variance,\n",
    "                'n_samples': len(valid_data)\n",
    "            }\n",
    "            \n",
    "            print(f\"{section}: {total_variance:.3f} total variance explained\")\n",
    "            print(f\"Top 5 components: {variance_ratios[:5]}\")\n",
    "            print(f\"Training samples: {len(valid_data)}\")\n",
    "            \n",
    "            # Quality check\n",
    "            if total_variance < 0.85:  # Expect >85% for 30 components\n",
    "                print(f\"WARNING: {section} PCA30 only retains {total_variance:.1%} variance\")\n",
    "        else:\n",
    "            print(f\"WARNING: No valid samples found for {section} section!\")\n",
    "            pca_models[section] = None\n",
    "    \n",
    "    return pca_models, pca_explained_variance\n",
    "\n",
    "# Test the function\n",
    "# pca_models, pca_variance = train_pca30_models([stage1_results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daee8d9b",
   "metadata": {},
   "source": [
    "# Step-9: Transform with PCA30\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f5aa5f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def transform_with_pca30(pe_results, section, pca_model, n_components=30):\n",
    "    \"\"\"\n",
    "    Transform single PE file section using trained PCA30\n",
    "    \"\"\"\n",
    "    if pe_results[section]['status'] == 'found' and pca_model is not None:\n",
    "        # Extract and flatten 8x8 section image\n",
    "        img_8x8 = pe_results[section]['array']\n",
    "        flattened = img_8x8.flatten()  # Shape: (64,)\n",
    "        \n",
    "        # Apply PCA30: 64 → 30 features\n",
    "        pca30_features = pca_model.transform([flattened])[0]  # Shape: (30,)\n",
    "        return pca30_features\n",
    "    else:\n",
    "        # Missing section: return -1 vector (as per paper)\n",
    "        return np.full(n_components, -1.0)\n",
    "\n",
    "# Test the function\n",
    "# pca30_features = transform_with_pca30(stage1_results, '.text', pca_models['.text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f07317e",
   "metadata": {},
   "source": [
    "# Step-10: Angular Embedding Preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bec148",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_for_angular_embedding(pca30_features):\n",
    "    \"\"\"\n",
    "    Map PCA30 features to [0, π/2] range for Angular Hybrid Embedding\n",
    "    \"\"\"\n",
    "    # Handle missing sections (-1 values) separately\n",
    "    if np.all(pca30_features == -1):\n",
    "        return pca30_features  # Keep missing sections as -1\n",
    "    \n",
    "    # Scale valid features to [0, π/2]\n",
    "    scaler = MinMaxScaler(feature_range=(0, np.pi/2))\n",
    "    scaled_features = scaler.fit_transform(pca30_features.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    return scaled_features\n",
    "\n",
    "def configure_angular_hybrid_embedding(pca30_features):\n",
    "    \"\"\"\n",
    "    Configure PCA30 features for Angular-Hybrid4 embedding\n",
    "    Split 30 PCA features into 2 groups of 15\n",
    "    \"\"\"\n",
    "    N = 15  # 15 classical data points per 4-qubit block\n",
    "    \n",
    "    if len(pca30_features) == 30:\n",
    "        # Split 30 features into two 15-feature groups\n",
    "        X1 = pca30_features[:N]   # First 15 features for qubits [0,1,2,3]\n",
    "        X2 = pca30_features[N:]   # Last 15 features for qubits [4,5,6,7]\n",
    "        return X1, X2\n",
    "    else:\n",
    "        raise ValueError(f\"Expected 30 features, got {len(pca30_features)}\")\n",
    "\n",
    "# Test the functions\n",
    "# angular_features = prepare_for_angular_embedding(pca30_features)\n",
    "# X1, X2 = configure_angular_hybrid_embedding(angular_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4dc4aa",
   "metadata": {},
   "source": [
    "# Step-11: Single File to Angular Embedding\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbe61b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def process_single_pe_to_angular_embedding(pe_results, pca_models, n_components=30):\n",
    "    \"\"\"\n",
    "    Complete Stage 2 pipeline for single PE file:\n",
    "    8x8 images → PCA30 → Angular scaling → Angular-Hybrid4 configuration\n",
    "    \"\"\"\n",
    "    target_sections = [\".text\", \".data\", \".rdata\", \".rsrc\", \".reloc\"]\n",
    "    stage2_output = {}\n",
    "    \n",
    "    for section in target_sections:\n",
    "        # Step 1: 8x8 image → 64 features → 30 PCA features\n",
    "        pca30_features = transform_with_pca30(pe_results, section, pca_models[section], n_components)\n",
    "        \n",
    "        # Step 2: Scale to [0, π/2] for quantum encoding\n",
    "        angular_features = prepare_for_angular_embedding(pca30_features)\n",
    "        \n",
    "        # Step 3: Configure for Angular-Hybrid4 embedding (30 → 2×15)\n",
    "        if not np.all(angular_features == -1):\n",
    "            X1, X2 = configure_angular_hybrid_embedding(angular_features)\n",
    "            stage2_output[section] = {\n",
    "                'X1': X1,  # 15 features for qubits [0,1,2,3]\n",
    "                'X2': X2,  # 15 features for qubits [4,5,6,7]\n",
    "                'encoding_type': 'Angular-Hybrid4',\n",
    "                'missing': False,\n",
    "                'pca30_features': pca30_features,\n",
    "                'angular_features': angular_features\n",
    "            }\n",
    "        else:\n",
    "            stage2_output[section] = {\n",
    "                'X1': np.full(15, -1.0),\n",
    "                'X2': np.full(15, -1.0),\n",
    "                'encoding_type': 'missing_section',\n",
    "                'missing': True,\n",
    "                'pca30_features': pca30_features,\n",
    "                'angular_features': angular_features\n",
    "            }\n",
    "    \n",
    "    return stage2_output\n",
    "\n",
    "# Test the function\n",
    "# stage2_results = process_single_pe_to_angular_embedding(stage1_results, pca_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d800f2da",
   "metadata": {},
   "source": [
    "# Step-12: Batch Processing Function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee0cc9d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def batch_process_to_angular_embedding(dataset_results, pca_models, n_components=30):\n",
    "    \"\"\"\n",
    "    Process multiple PE files through complete Stage-2 pipeline\n",
    "    \"\"\"\n",
    "    angular_embedding_dataset = []\n",
    "    \n",
    "    for i, pe_results in enumerate(dataset_results):\n",
    "        stage2_output = process_single_pe_to_angular_embedding(pe_results, pca_models, n_components)\n",
    "        angular_embedding_dataset.append(stage2_output)\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1} PE files through Stage-2 pipeline\")\n",
    "    \n",
    "    return angular_embedding_dataset\n",
    "\n",
    "# Test the function\n",
    "# angular_dataset = batch_process_to_angular_embedding([stage1_results], pca_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d70f92e",
   "metadata": {},
   "source": [
    "# Step-13: Angular Hybrid Quantum Encoding Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da58bbac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import pennylane as qml\n",
    "    PENNYLANE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"PennyLane not available - quantum encoding functions will be placeholders\")\n",
    "    PENNYLANE_AVAILABLE = False\n",
    "\n",
    "def Angular_Hybrid_4(X, wires):\n",
    "    \"\"\"\n",
    "    Implements Angular Hybrid embedding for 4 qubits\n",
    "    Encodes 15 classical features into 4-qubit quantum state\n",
    "    \"\"\"\n",
    "    if not PENNYLANE_AVAILABLE:\n",
    "        return f\"Angular_Hybrid_4 encoding with {len(X)} features on wires {wires}\"\n",
    "    \n",
    "    qml.RY(X[0], wires=wires[0])\n",
    "\n",
    "    qml.PauliX(wires=wires[0])\n",
    "    qml.CRY(X[1], wires=[wires[0], wires[1]])\n",
    "    qml.PauliX(wires=wires[0])\n",
    "    qml.CRY(X[2], wires=[wires[0], wires[1]])\n",
    "\n",
    "    qml.RY(X[3], wires=wires[2])\n",
    "    qml.CNOT(wires=[wires[1], wires[2]])\n",
    "    qml.RY(X[4], wires=wires[2])\n",
    "    qml.CNOT(wires=[wires[0], wires[2]])\n",
    "    qml.RY(X[5], wires=wires[2])\n",
    "    qml.CNOT(wires=[wires[1], wires[2]])\n",
    "    qml.RY(X[6], wires=wires[2])\n",
    "    qml.CNOT(wires=[wires[0], wires[2]])\n",
    "\n",
    "    qml.RY(X[7], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[2], wires[3]])\n",
    "    qml.RY(X[8], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[1], wires[3]])\n",
    "    qml.RY(X[9], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[2], wires[3]])\n",
    "    qml.RY(X[10], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[0], wires[3]])\n",
    "    qml.RY(X[11], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[2], wires[3]])\n",
    "    qml.RY(X[12], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[1], wires[3]])\n",
    "    qml.RY(X[13], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[2], wires[3]])\n",
    "    qml.RY(X[14], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[0], wires[3]])\n",
    "\n",
    "def encode_section_to_quantum_state(section_embedding_data, section_name):\n",
    "    \"\"\"\n",
    "    Encode one section's PCA30 features to 8-qubit quantum state\n",
    "    Using Angular-Hybrid4 embedding strategy\n",
    "    \"\"\"\n",
    "    X1 = section_embedding_data['X1']  # 15 features\n",
    "    X2 = section_embedding_data['X2']  # 15 features\n",
    "    \n",
    "    if section_embedding_data['missing']:\n",
    "        # Missing section: use special encoding\n",
    "        print(f\"Encoding missing {section_name} section\")\n",
    "        return {\n",
    "            'encoding_type': 'missing_section',\n",
    "            'quantum_circuit': None,\n",
    "            'description': f\"Missing {section_name} section - no quantum encoding\"\n",
    "        }\n",
    "    else:\n",
    "        # Valid section: use Angular Hybrid embedding\n",
    "        if PENNYLANE_AVAILABLE:\n",
    "            # Create quantum circuit for this section\n",
    "            circuit_description = {\n",
    "                'block1': f\"Angular_Hybrid_4(X1, wires=[0, 1, 2, 3]) with {len(X1)} features\",\n",
    "                'block2': f\"Angular_Hybrid_4(X2, wires=[4, 5, 6, 7]) with {len(X2)} features\"\n",
    "            }\n",
    "        else:\n",
    "            circuit_description = {\n",
    "                'block1': f\"Angular_Hybrid_4 placeholder for {len(X1)} features\",\n",
    "                'block2': f\"Angular_Hybrid_4 placeholder for {len(X2)} features\"\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            'encoding_type': 'Angular-Hybrid4',\n",
    "            'quantum_circuit': circuit_description,\n",
    "            'description': f\"8-qubit encoding for {section_name} section\"\n",
    "        }\n",
    "\n",
    "print(\"Angular Hybrid Quantum Encoder functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5538a0",
   "metadata": {},
   "source": [
    "# Step-14: Complete Pipeline Integration Function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ad880",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def complete_bodmas_pipeline(pe_file_paths, labels, save_stage1_images=False, n_components=30):\n",
    "    \"\"\"\n",
    "    Complete BODMAS preprocessing pipeline integrating Stage-1 and Stage-2\n",
    "    PE Files → Section Extraction → 8x8 Images → PCA30 → Angular Hybrid Embedding\n",
    "    \"\"\"\n",
    "    print(f\"Processing {len(pe_file_paths)} PE files through complete BODMAS pipeline...\")\n",
    "    \n",
    "    # Stage-1: Process all PE files to 8x8 section images\n",
    "    print(\"\\n=== STAGE-1: PE Section Extraction ===\")\n",
    "    training_results = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for i, pe_file in enumerate(pe_file_paths):\n",
    "        try:\n",
    "            section_results = complete_stage1_processing(\n",
    "                pe_file, save_images=save_stage1_images\n",
    "            )\n",
    "            \n",
    "            if section_results:\n",
    "                training_results.append(section_results)\n",
    "                valid_indices.append(i)\n",
    "                \n",
    "                if (i + 1) % 50 == 0:\n",
    "                    print(f\"Stage-1 processed {i + 1}/{len(pe_file_paths)} files\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pe_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Stage-1 completed: {len(training_results)} valid PE files\")\n",
    "    \n",
    "    # Stage-2: Train PCA30 models\n",
    "    print(\"\\n=== STAGE-2: PCA30 Model Training ===\")\n",
    "    pca_models, pca_explained_variance = train_pca30_models(training_results, n_components)\n",
    "    \n",
    "    # Stage-2: Transform training data to Angular Hybrid embedding\n",
    "    print(\"\\n=== STAGE-2: Angular Hybrid Embedding ===\")\n",
    "    angular_training_data = batch_process_to_angular_embedding(training_results, pca_models, n_components)\n",
    "    \n",
    "    # Filter labels for valid samples\n",
    "    valid_labels = [labels[i] for i in valid_indices]\n",
    "    \n",
    "    return {\n",
    "        'stage1_results': training_results,\n",
    "        'angular_embedding_data': angular_training_data,\n",
    "        'valid_labels': valid_labels,\n",
    "        'valid_indices': valid_indices,\n",
    "        'pca_models': pca_models,\n",
    "        'pca_explained_variance': pca_explained_variance\n",
    "    }\n",
    "\n",
    "# Test the complete pipeline\n",
    "# pipeline_results = complete_bodmas_pipeline([\"sample1.exe\", \"sample2.exe\"], [1, 0])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
